---
title: "importance_mixed_effects"
author: "Josh Marvald"
date: "6/9/2020"
output: html_document
---

```{r}
library(tidyverse)
library(lme4)
source("data_cleaning.R")
```

```{r}
# keep matches where both players having enough matches

# atp
players_keep_atp <- 
  final_atp_df1 %>% 
  group_by(match_id) %>%
  slice(1) %>%
  ungroup() %>%
  pivot_longer(c(player1, player2), names_to = "player", values_to = "name") %>%
  group_by(name) %>%
  summarise(nmatches = n()) %>%
  filter(nmatches >= 15 & is.na(name) == FALSE)

atp_mod_df <- 
  final_atp_df1 %>% 
  filter(player1 %in% players_keep_atp$name & player2 %in% players_keep_atp$name) %>% 
  mutate(servingplayer = case_when(PointServer == 1 ~ player1, PointServer == 2 ~ player2)) %>%
  mutate(returningplayer = case_when(PointServer == 1 ~ player2, PointServer == 2 ~ player1)) %>%
  filter(is.na(importance2) == FALSE)

# wta
players_keep_wta <- 
  final_wta_df1 %>% 
  group_by(match_id) %>%
  slice(1) %>%
  ungroup() %>%
  pivot_longer(c(player1, player2), names_to = "player", values_to = "name") %>%
  group_by(name) %>%
  summarise(nmatches = n()) %>%
  filter(nmatches >= 13 & is.na(name) == FALSE)

wta_mod_df <- 
  final_wta_df1 %>% 
  filter(player1 %in% players_keep_wta$name & player2 %in% players_keep_wta$name) %>% 
  mutate(servingplayer = case_when(PointServer == 1 ~ player1, PointServer == 2 ~ player2)) %>%
  mutate(returningplayer = case_when(PointServer == 1 ~ player2, PointServer == 2 ~ player1)) %>%
  filter(is.na(importance2) == FALSE)
```


```{r}
# split data
set.seed(7) 


# make variable for row number
atp_mod_df$rowID <- 1:nrow(atp_mod_df)
wta_mod_df$rowID <- 1:nrow(wta_mod_df)


# sample for training data
atp_train_df <- 
  atp_mod_df[sample(1:nrow(atp_mod_df), 9000, replace = FALSE), ]

# take the rows in whole data set not in training data set
atp_test_df <-
  anti_join(atp_mod_df, atp_train_df, by = "rowID")


# sample for training data
wta_train_df <-
  wta_mod_df[sample(1:nrow(wta_mod_df), 3500, replace = FALSE),]

# take the rows in whole data set not in training data set
wta_test_df <-
  anti_join(wta_mod_df, wta_train_df, by = "rowID")

```


```{r}
# fit model

atp_mod_basic <- lmer(Speed_MPH ~ importance2 + (1 + importance2 | servingplayer), data = atp_train_df)

atp_mod_basic2 <- lmer(Speed_MPH ~  (1 | servingplayer), data = atp_train_df)

atp_mod_basic3 <- lmer(Speed_MPH ~ importance2 + (1 | servingplayer), data = atp_train_df)
```


```{r}
# data from for predictions
predictions <- 
  data.frame(predict(atp_mod_basic, atp_test_df)) %>%
  mutate(pred = predict.atp_mod_basic..atp_test_df.) %>%
  within(., rm(predict.atp_mod_basic..atp_test_df.))

predictions2 <- data.frame(predict(atp_mod_basic2, atp_test_df)) %>%
  mutate(pred2 = predict.atp_mod_basic2..atp_test_df.) %>%
  within(., rm(predict.atp_mod_basic2..atp_test_df.))

predictions3 <- data.frame(predict(atp_mod_basic3, atp_test_df)) %>%
  mutate(pred3 = predict.atp_mod_basic3..atp_test_df.) %>%
  within(., rm(predict.atp_mod_basic3..atp_test_df.))

# add predictions to testing data frame
atp_test_df <-
  bind_cols(atp_test_df, predictions, predictions2, predictions3) %>%
  mutate(diff = Speed_MPH - pred, diff2 = Speed_MPH - pred2, diff3 = Speed_MPH - pred3) %>%
  select(Speed_MPH, pred, diff, diff2, diff3, importance2, everything())


ggplot(data = atp_test_df, aes(x = diff)) + geom_histogram()
ggplot(data = atp_test_df, aes(x = diff2)) + geom_histogram()
```


```{r}
mod_stats <-
  atp_test_df %>%
  ungroup() %>%
  summarise(avg_res1 = mean(diff),
            avg_res2 = mean(diff2),
            avg_res3 = mean(diff3),
            sd_res1 = sd(diff),
            sd_res2 = sd(diff2),
            sd_res3 = sd(diff3),
            mae1 = (sum(abs(diff)))/n(),
            mae2 = (sum(abs(diff2)))/n(),
            mae3 = (sum(abs(diff3)))/n(),
            mse1 = (sum(diff^2))/n(),
            mse2 = (sum(diff2^2))/n(),
            mse3 = (sum(diff3^2))/n())
```

Evaluating Models

One thing you can think about is: if you were to predict speed without using importance (using a random effects model with only player, taking out the importance2 terms), would the predictions from this model be just as good? If yes, then importance isn't super important. If not, then importance is important. 

In order to evaluate what models "better", you can just start with the metrics from STAT 213. Use your `diff` column to see which model has the smaller standard deviation of the residuals. And make a couple of new variables for mean square prediction error and mean absolute error....I think Jessica and I did very similar things with prediction in STAT 213 but let me know if these aren't familiar.

You can then do the same thing with a model with a random effect for player and a fixed effect for importance. This model assumes that players have differing mean serve speeds (which they obviously do) but that the importance of the point affects each player in the same way (so that everyone has the same slope). If this modle performs the best, then that's evidence that importance is "important" (haha) in predicting serve speed but that each player responds in a similar way to point importance regarding his / her serve.

