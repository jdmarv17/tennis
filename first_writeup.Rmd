---
title: "Exploration_process"
author: "Josh Marvald"
date: "6/5/2020"
output: html_document
---

  To begin my project, I started by exploring both match and point data. Before going into the exploration process it is important to understand the data involved. The first of the three data sets involved is match data from the past decade of Grand Slam matches for the ATP and WTA. The match data includes summary statistics from every Grand Slam match. The statistics most useful for this project are first and second serve percentages and the ranking of each player in the match. The second data set utilized in this project is point-by-point data from 2016 and 2017 Grand Slam matches. This data has information on each point played in every Grand Slam from 2016 and 2017. Some of the variables include serve speed, serve placement, rally count, and the current score of the point. The last data set used is a data set of point importance for each possible score in tennis. Importance values for a point give the average change in the probability of the winner of the point winning the match. Point importance will play an important role by being used as a predictor of different serve measurements in one of the models I will build for the project. During the data manipulation/cleaning period the importance data set was merged by score with the Grand Slam point-by-point data to assign importance values to each point played in Grand Slams.
  
  Exploring this data consisted of looking for any trends in the data. Specifically, any trends that were related to the serve in some way were of particular interest. To find these trends I had to manipulate the data sets into more usable forms. For example, the match data was originally in a form where each player in the match was listed in each row. To make it easier to look for trends in the data it was necessary to pivot the data into long form where only the winner or loser is listed. While this esentially doubled the matches in the data set, it was only used to look for trends. The model we will build for the match data uses the shorter form of the data.
  
  Once some manipulation had been done with the match data we were able to look for any relationships between first and second serve and the probability of a given player winning a match. Surprisingly we found patterns that indicated that for some players, higher first serve percentages corresponded with lower chances of winning a match.
  
```{r, echo=FALSE}
ggplot(matches_to_facet2, aes(x = first_serve, y = win)) +
  geom_jitter(height = 0.12, alpha = 0.15) +
  stat_smooth(method = "glm", method.args = c("binomial")) +
  facet_wrap("player")
```
  
  At this point we realized that there were other factors in play that must be contributing to this trend. Given a single match it doesn't make much sense that a higher first serve percentage would decrease a player's chance of winning. Our first theory was that it was possible that players were serving differently against lower and higher ranked players. Specifically our theory was that they might serve faster and less acurately against lower ranked players and slower and more accurately against higher ranked players. This could account for having more matches won with lower first serve percentages and more matches lost with higher first serve percentages. To see if this was the case we made a categorical variable for the opponent's ranking.
  
```{r, echo=FALSE}
ggplot(matches_to_facet2, aes(x = first_serve, y = win, color = opponent_ranking)) +
  geom_jitter(height = 0.12, alpha = 0.15) +
  stat_smooth(method = "glm", method.args = c("binomial")) +
  facet_wrap("player")
```
  As we can see from the plots above, this did not help simplify the matter. Different players have different trends and most players don't have the same trend for each category of opponent ranking. Seeing that looking at opponent ranking wasn't enough we realized that a more opponent specific model would be needed. This is what led us to decide on a Bradley-Terry model. This type of model takes a given player and looks at the matches they played against all opponents and returns different lines for different player match ups. This model allows for a possibility that less specific models would reveal. Specifically, it is possible for a given player to have an overall negative relationship between their chance of winning a match and first serve percent while still having a positive relationship between chance of winning and first serve percent against specific opponents. While this may not be the case for all players, it is a possibility that may not be accounted for with other types of models.
  
  Moving on to the point data, the exploration process was not as involved. The only relationship we were looking was point importance vs serve speed and serve placement. The more time consuming process turned out to be manipulating the importance data and the point-by-point data to merge correctly. The importance data set was calculated using the assumption that a tiebreaker would be played at 6-6 in a fifth set; however, in some grandslam tournaments no tiebreaker is played for the fifth set. Instead of a tiebreaker, play continues until one player leads the other by two games. Since this was the case, upon merging the point-by-point with the importance data there were points in some matches that were not assigned importance values due to the fact that no fifth set tiebreaker was played. To account for this we created a grouping variable that accounted for the difference in players' game scores in the fifth set once the score of 6-6 was reached. Once this was done we grouped the merged data by point score and the grouping variable and filled in the missing importance values based on the groupings.


